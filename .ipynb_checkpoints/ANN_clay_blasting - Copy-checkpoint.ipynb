{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3b3c27b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1370238f4b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from torch.autograd import Variable\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from fastprogress import master_bar, progress_bar\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7446441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cf8758",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a67f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "043a2095",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_w = \"input_data/input_data_weather.xlsx\"\n",
    "\n",
    "file_path_blast = \"input_data/input_data_blasting.xlsx\"\n",
    "\n",
    "df_w = pd.read_excel(file_path_w, index_col = \"Date\")\n",
    "df_b = pd.read_excel(file_path_blast, parse_dates=[\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3b0185c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3653, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data_w = df_w\n",
    "\n",
    "model_data_w.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abd4cf28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_b.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "654a8dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data_w(arr, seq_len_in, seq_len_out, input_size):\n",
    "    x, y = [], []\n",
    "    \n",
    "    for i in range(len(arr)-(seq_len_in+seq_len_out)): # len(df)-(seq_len_in+seq_len_out)\n",
    "        \n",
    "        x_i = arr[i : i+seq_len_in+1, 1:input_size+1]  # \n",
    "        y_i = arr[i + seq_len_in : i + seq_len_in + seq_len_out,0]\n",
    "        x.append(x_i)\n",
    "        y.append(y_i)\n",
    "    x_arr = np.array(x).reshape(-1, seq_len_in+1, input_size).astype(\"float32\")\n",
    "    y_arr = np.array(y).reshape(-1, seq_len_out).astype(\"float32\")\n",
    "    x_var = Variable(torch.from_numpy(x_arr))\n",
    "    y_var = Variable(torch.from_numpy(y_arr))\n",
    "    return x_var, y_var\n",
    "\n",
    "# nejde od nečega do ite vrijednosti u nizu, nego od datuma interesa - 100 dana, do datuma interesa, \n",
    "# hard-codea se datum interesa, \n",
    "# umjesto i, i onda nebu svaki outa drugi niz brojeva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e2eb7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4551f230",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Blasting_dataset(Dataset):\n",
    "    def __init__(self):\n",
    "        # data laoding\n",
    "        arr_w = pd.read_excel(\"input_data/input_data_weather.xlsx\", index_col = \"Date\").values\n",
    "        arr_b = pd.read_excel(\"input_data/input_data_blasting.xlsx\", parse_dates=[\"Date\"]).values\n",
    "        \n",
    "        self_x_b = torc.from_numpy(arr_b[:, 3:]) \n",
    "        \n",
    "        \n",
    "        self.x_w = torch.from_numpy(arr_w) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7948aa67",
   "metadata": {},
   "source": [
    "####\n",
    "\n",
    "Sve u jedan dataset, iz drugog, ide jedan po jedan redak, gleda datum, to mu je krajnji datum koji gleda u prvo setu,\n",
    "zatim iz prvog seta uzme vrijednosti -100 od toga datuma i do njega, te njih provrti kroz LSTM, te torch.cat sa drugim podacima i pusti kroz dense layere (2-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "72c8bfbd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Explosive\\nCharge Mass  Stemming Length  Borehole Depth  \\\n",
      "0  2014-06-12                    1.25              1.0            2.03   \n",
      "1  2014-06-12                    0.50              1.0            2.09   \n",
      "2  2014-06-12                    1.00              1.0            2.01   \n",
      "3  2014-06-12                    0.80              1.0            1.98   \n",
      "4  2014-06-12                    0.60              1.0            2.07   \n",
      "5  2014-06-12                    0.40              1.0            1.94   \n",
      "6  2014-06-12                    0.40              1.0            1.98   \n",
      "7  2014-06-12                    0.60              1.0            1.94   \n",
      "8  2014-06-12                    0.80              1.0            1.94   \n",
      "9  2014-06-12                    1.00              1.0            2.02   \n",
      "10 2016-07-20                    0.20              0.5            2.44   \n",
      "11 2016-07-20                    0.20              0.5            2.52   \n",
      "12 2016-07-20                    0.40              0.5            2.47   \n",
      "13 2016-07-20                    0.40              0.5            2.53   \n",
      "14 2016-07-20                    0.60              0.5            2.51   \n",
      "15 2016-07-20                    0.80              0.5            2.18   \n",
      "16 2016-07-20                    0.80              0.5            2.20   \n",
      "17 2016-07-20                    1.00              0.5            2.54   \n",
      "18 2016-07-20                    0.40              0.5            2.52   \n",
      "19 2016-07-20                    0.20              0.5            1.90   \n",
      "20 2016-07-20                    0.60              0.5            2.22   \n",
      "21 2016-07-20                    0.80              0.5            2.26   \n",
      "22 2016-07-20                    0.60              0.5            2.31   \n",
      "23 2016-07-20                    0.80              0.5            2.34   \n",
      "24 2016-07-20                    0.40              0.5            2.19   \n",
      "25 2016-07-20                    0.20              0.5            2.18   \n",
      "26 2016-07-20                    0.20              0.5            2.01   \n",
      "\n",
      "    Dubina minske bušotine nakon miniranja  Volumen nastalog proširenja  \\\n",
      "0                                     2.43                       872.20   \n",
      "1                                     2.36                       371.65   \n",
      "2                                     2.44                       751.65   \n",
      "3                                     2.38                       574.70   \n",
      "4                                     2.41                       507.10   \n",
      "5                                     2.23                       461.55   \n",
      "6                                     2.20                       323.00   \n",
      "7                                     2.22                       436.96   \n",
      "8                                     2.36                       656.95   \n",
      "9                                     2.48                       835.50   \n",
      "10                                    2.62                       100.50   \n",
      "11                                    2.74                        64.50   \n",
      "12                                    2.78                       244.50   \n",
      "13                                    2.83                       194.50   \n",
      "14                                    2.85                       616.00   \n",
      "15                                    2.64                       344.00   \n",
      "16                                    2.68                       362.60   \n",
      "17                                    3.06                       710.00   \n",
      "18                                    2.76                       292.50   \n",
      "19                                    2.16                        82.50   \n",
      "20                                    2.59                       527.60   \n",
      "21                                    2.57                       618.40   \n",
      "22                                    2.60                       633.00   \n",
      "23                                    2.70                       569.00   \n",
      "24                                    2.51                       216.00   \n",
      "25                                    2.40                        70.00   \n",
      "26                                    2.25                        98.00   \n",
      "\n",
      "    Volumen cijele minske bušotine  Volumen nastalog proširenja.1  \\\n",
      "0                           883.80                        0.87220   \n",
      "1                           395.20                        0.37165   \n",
      "2                           758.90                        0.75165   \n",
      "3                           589.20                        0.57470   \n",
      "4                           523.05                        0.50710   \n",
      "5                           476.55                        0.46155   \n",
      "6                           335.50                        0.32300   \n",
      "7                           454.21                        0.43696   \n",
      "8                           669.20                        0.65695   \n",
      "9                           849.90                        0.83550   \n",
      "10                          127.00                        0.10050   \n",
      "11                           93.00                        0.06450   \n",
      "12                          264.00                        0.24450   \n",
      "13                          219.00                        0.19450   \n",
      "14                          632.00                        0.61600   \n",
      "15                          363.00                        0.34400   \n",
      "16                          374.75                        0.36260   \n",
      "17                          723.50                        0.71000   \n",
      "18                          318.00                        0.29250   \n",
      "19                          101.50                        0.08250   \n",
      "20                          543.75                        0.59415   \n",
      "21                          635.70                        0.61840   \n",
      "22                          681.50                        0.63300   \n",
      "23                          589.50                        0.56900   \n",
      "24                          231.50                        0.21600   \n",
      "25                           90.50                        0.07000   \n",
      "26                          118.50                        0.09800   \n",
      "\n",
      "    Volumen cijele minske bušotine.1  Produbljenje  Proširenje  \n",
      "0                            0.88380          0.40       1.193  \n",
      "1                            0.39520          0.27       1.006  \n",
      "2                            0.75890          0.43       1.254  \n",
      "3                            0.58920          0.40       1.169  \n",
      "4                            0.52305          0.34       1.153  \n",
      "5                            0.47655          0.26       1.045  \n",
      "6                            0.33550          0.22       0.881  \n",
      "7                            0.45421          0.28       1.096  \n",
      "8                            0.66920          0.42       1.129  \n",
      "9                            0.84990          0.46       1.140  \n",
      "10                           0.12700          0.18       0.576  \n",
      "11                           0.09300          0.22       0.577  \n",
      "12                           0.26400          0.31       0.698  \n",
      "13                           0.21900          0.30       0.787  \n",
      "14                           0.63200          0.34       1.043  \n",
      "15                           0.36300          0.46       0.877  \n",
      "16                           0.37475          0.48       0.875  \n",
      "17                           0.72350          0.52       1.157  \n",
      "18                           0.31800          0.26       0.936  \n",
      "19                           0.10150          0.26       0.557  \n",
      "20                           0.61140          0.35       1.104  \n",
      "21                           0.63570          0.31       1.190  \n",
      "22                           0.68150          0.29       1.085  \n",
      "23                           0.58950          0.36       1.131  \n",
      "24                           0.23150          0.32       0.585  \n",
      "25                           0.09050          0.22       0.505  \n",
      "26                           0.11850          0.24       0.687  \n",
      "         Date  Explosive\\nCharge Mass  Stemming Length  Borehole Depth  \\\n",
      "27 2015-06-12                     1.6              1.0            3.07   \n",
      "28 2015-06-12                     0.2              0.3            3.04   \n",
      "29 2015-06-12                     0.4              0.3            3.05   \n",
      "30 2015-06-12                     0.8              0.5            2.87   \n",
      "31 2015-06-12                     0.6              0.5            2.80   \n",
      "32 2015-06-12                     0.4              0.5            3.07   \n",
      "\n",
      "    Dubina minske bušotine nakon miniranja  Volumen nastalog proširenja  \\\n",
      "27                                    3.58                        807.0   \n",
      "28                                    3.20                         80.5   \n",
      "29                                    3.28                        154.5   \n",
      "30                                    3.20                        393.5   \n",
      "31                                    3.05                        255.5   \n",
      "32                                    3.30                        113.5   \n",
      "\n",
      "    Volumen cijele minske bušotine  Volumen nastalog proširenja.1  \\\n",
      "27                           844.5                         0.8070   \n",
      "28                           111.5                         0.0805   \n",
      "29                           188.0                         0.1545   \n",
      "30                           417.4                         0.3935   \n",
      "31                           281.0                         0.2555   \n",
      "32                           151.0                         0.1135   \n",
      "\n",
      "    Volumen cijele minske bušotine.1  Produbljenje  Proširenje  \n",
      "27                            0.8445          0.51       1.169  \n",
      "28                            0.1115          0.16       0.584  \n",
      "29                            0.1880          0.23       0.670  \n",
      "30                            0.4174          0.33       0.953  \n",
      "31                            0.2810          0.25       0.783  \n",
      "32                            0.1510          0.23       0.693  \n"
     ]
    }
   ],
   "source": [
    "def train_val_test_split(train_end_idx =27, \n",
    "                         val_start_idx=27, \n",
    "                         test_start_idx=33,\n",
    "                         seq_len_in=1, seq_len_out=1, input_size=1):\n",
    "        \n",
    "        df_w = pd.read_excel(\"input_data/input_data_weather.xlsx\", index_col = \"Date\")\n",
    "        df_b = pd.read_excel(\"input_data/input_data_blasting.xlsx\", parse_dates=[\"Date\"])\n",
    "        \n",
    "        \n",
    "        w_scaler, df_scaler, b_scaler = StandardScaler(), StandardScaler(), StandardScaler()\n",
    "        \n",
    "        df_train_b = df_b.iloc[:train_end_idx]\n",
    "        print (df_train_b)\n",
    "        df_valid_b = df_b.iloc[val_start_idx:test_start_idx]\n",
    "        print (df_valid_b)\n",
    "        df_test_b =  df_b.iloc[test_start_idx:]\n",
    "        \n",
    "        df_train_w = df_w.loc[df_train_b[\"Date\"].iloc[0]-pd.Timedelta(days=200):df_train_b[\"Date\"].iloc[0]]\n",
    "        df_valid_w = df_w.loc[df_valid_b[\"Date\"].iloc[0]-pd.Timedelta(days=200):df_valid_b[\"Date\"].iloc[0]]\n",
    "        df_test_w = df_w.loc[df_test_b[\"Date\"].iloc[0]-pd.Timedelta(days=200):df_test_b[\"Date\"].iloc[0]]\n",
    "                \n",
    "        train_b_scaled = df_scaler.fit_transform(df_train_b.iloc[:, 1:]).astype(np.float32)\n",
    "        valid_b_scaled = df_scaler.fit_transform(df_valid_b.iloc[:, 1:]).astype(np.float32)\n",
    "        test_b_scaled = df_scaler.fit_transform(df_test_b.iloc[:, 1:]).astype(np.float32)\n",
    "        \n",
    "        _ = b_scaler.fit(np.array(df_train_b.iloc[:, 1:3]).reshape(-1,2))\n",
    "        \n",
    "        train_w_scaled = w_scaler.fit_transform(df_train_w)\n",
    "        valid_w_scaled = w_scaler.fit_transform(df_valid_w)\n",
    "        test_w_scaled = w_scaler.fit_transform(df_test_w)\n",
    "        \n",
    "        b_x_train, b_y_train = Variable(torch.from_numpy(train_b_scaled[:, 2:])), Variable(torch.from_numpy(train_b_scaled[:, :2]))\n",
    "        b_x_valid, b_y_valid = Variable(torch.from_numpy(valid_b_scaled[:, 2:])), Variable(torch.from_numpy(valid_b_scaled[:, :2]))\n",
    "        b_x_test, b_y_test = Variable(torch.from_numpy(test_b_scaled[:, 2:])), Variable(torch.from_numpy(test_b_scaled[:, :2]))\n",
    "        \n",
    "        train_b_ds = TensorDataset(b_x_train, b_y_train)\n",
    "        valid_b_ds = TensorDataset(b_x_valid, b_y_valid)\n",
    "        test_b_ds = TensorDataset(b_x_test, b_y_test)\n",
    "        \n",
    "        train_w_ds = Variable(torch.from_numpy(train_w_scaled)).repeat(len(b_x_train),1,1).float()\n",
    "        valid_w_ds = Variable(torch.from_numpy(train_w_scaled)).repeat(len(b_x_valid),1,1).float()\n",
    "        test_w_ds = Variable(torch.from_numpy(train_w_scaled)).repeat(len(b_x_test),1,1).float()\n",
    "        \n",
    "        train_loader_b = torch.utils.data.DataLoader(train_b_ds, num_workers=0)\n",
    "        valid_loader_b = torch.utils.data.DataLoader(valid_b_ds, num_workers=0)\n",
    "        test_loader_b = torch.utils.data.DataLoader(test_b_ds, num_workers=0)\n",
    "        \n",
    "        train_loader_w = torch.utils.data.DataLoader(train_w_ds, num_workers=0)\n",
    "        valid_loader_w = torch.utils.data.DataLoader(valid_w_ds, num_workers=0)\n",
    "        test_loader_w = torch.utils.data.DataLoader(test_w_ds, num_workers=0)\n",
    "\n",
    "        return (train_loader_b, valid_loader_b, test_loader_b, train_loader_w, valid_loader_w, \n",
    "    test_loader_w, df_scaler, b_scaler, test_b_ds, test_w_ds, valid_w_ds, valid_b_ds, train_w_ds, train_b_ds)\n",
    "    \n",
    "    \n",
    "(train_loader_b, valid_loader_b, test_loader_b, train_loader_w, valid_loader_w, \n",
    " test_loader_w, df_scaler, b_scaler, test_b_ds, test_w_ds, valid_w_ds, valid_b_ds, train_w_ds, train_b_ds) = train_val_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f41a2e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataset.TensorDataset object at 0x00000137133D1C10>\n"
     ]
    }
   ],
   "source": [
    "print(test_b_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1acd5ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[-0.7781, -0.4361,  1.8600,  1.8478,  1.8393,  1.8266,  0.7925,  1.0775]]), tensor([[2.3147, 1.3038]])]\n"
     ]
    }
   ],
   "source": [
    "x_example = next(iter(train_loader_b))\n",
    "print (x_example) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2df77ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 201, 2])\n"
     ]
    }
   ],
   "source": [
    "x_example = next(iter(train_loader_w))\n",
    "print (x_example.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05647d0",
   "metadata": {},
   "source": [
    "### Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4525102c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Clay_NN(nn.Module):\n",
    "    def __init__(self, input_size_lstm, hidden_size_lstm, num_layers_lstm, device, input_size_b, dropout=0.3):\n",
    "        super(Clay_NN, self).__init__()\n",
    "        # Initializing the model parameters\n",
    "        self.input_size_lstm = input_size_lstm\n",
    "        self.hidden_size_lstm = hidden_size_lstm\n",
    "        self.num_layers_lstm = num_layers_lstm\n",
    "        self.input_b = input_size_b\n",
    "        self.device = device\n",
    "        # Layer 1: LSTM # batch_size first ()\n",
    "        self.lstm = nn.LSTM(self.input_size_lstm, self.hidden_size_lstm, \n",
    "                            self.num_layers_lstm, batch_first = True, dropout=dropout)\n",
    "        # Layer 2: Fully coneccted (linear) layer\n",
    "        self.linear_lstm = nn.Linear(self.hidden_size_lstm, 1)\n",
    "        # Relu activation after LSTM\n",
    "        self.relu1 = nn.ReLU()\n",
    "        # Fully coneccted (linear) layer 1 - blasting data\n",
    "        self.linear_b1 = nn.Linear(1+self.input_b, 5)\n",
    "        # Relu activation after 1st fully connected\n",
    "        self.relu2 = nn.ReLU()\n",
    "        # Fully coneccted (linear) layer 1 - blasting data\n",
    "        self.linear_b2 = nn.Linear(5, 2)\n",
    "        \n",
    "    def forward(self, input_w, input_b, prints = False):\n",
    "        # Reshaping the input_seq\n",
    "        input_w = input_w.view(-1, input_w.shape[1], self.input_size_lstm)\n",
    "        if prints: print(\"input_seq shape:\", input_w.shape, \"->[num_batches, seq_len, num_features]\")     \n",
    "        # LSTM \n",
    "        output_lstm, (h_state, c_state) = self.lstm(input_w)\n",
    "        if prints: print(\"LSTM: output shape:\" , output_lstm.shape, \"->[num_batches, seq_len, hidden_size]\", \n",
    "                         \"\\n \" \"LSTM: h_state shape:\", h_state.shape, \n",
    "                          \"->[num_layers*num_directions, num_batches, hidden_size]\", \"\\n\"\n",
    "                          \"LSTM: c_state shape:\", c_state.shape, \n",
    "                          \"->[num_layers*num_directions, num_batches, hidden_size]\")\n",
    "        # Reshape \n",
    "        output_lstm = output_lstm[:, -1, :]\n",
    "        if prints: print(\"Output reshaped:\", output_lstm.shape, \"->[num_batches, hidden_size]\")\n",
    "        # Fully connected layer\n",
    "        output_lstm = self.linear_lstm(output_lstm)\n",
    "        # Relu activation\n",
    "        output_lstm = self.relu1(output_lstm)\n",
    "        # Adding blasting data\n",
    "        if prints: print (\"LSTM: output shape:\", output_lstm.shape)\n",
    "        output = torch.cat((output_lstm, input_b), dim=1)        \n",
    "        # Blasting layer 1\n",
    "        output = self.linear_b1(output)\n",
    "        # Relu activation\n",
    "        output = self.relu2(output)\n",
    "        # Blasting layer 2\n",
    "        output = self.linear_b2(output)\n",
    "        \n",
    "        if prints: print(\"FNN: Final output shape:\", output.shape, \"->[num_batches, num_features]\")\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c49e1a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(save_dir, input_size, hidden_size, num_layers, seq_len_out, architecture = \"LSTM\", device = \"cpu\", dropout = 0.1):\n",
    "    if os.path.exists(save_dir):\n",
    "        if architecture == \"LSTM\":\n",
    "            model = LSTM(input_size, hidden_size, num_layers, seq_len_out, device)\n",
    "        else:\n",
    "            model = RNN(input_size, hidden_size, num_layers, seq_len_out, device)\n",
    "        model, prev_epochs, optimizer = model_loader(save_dir)\n",
    "        return model, prev_epochs, optimizer\n",
    "    else:\n",
    "        if architecture == \"LSTM\":\n",
    "            model = LSTM(input_size, hidden_size, num_layers, seq_len_out, device)\n",
    "        else:\n",
    "            model = RNN(input_size, hidden_size, num_layers, seq_len_out, device)\n",
    "        prev_epochs = 0\n",
    "        return model, prev_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea57e210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3815d9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(checkpoint, save_dir):\n",
    "    \"\"\"\n",
    "    Saving: model, optimizer, epochs, state dict\n",
    "    \"\"\"\n",
    "    print (\"Model has been saved.\")\n",
    "    return torch.save(checkpoint, save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2dc9e0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loader(file_pth, device = \"cpu\"):\n",
    "    \"\"\"\n",
    "    The function loads a checkpoint from the model. Either to continue\n",
    "    training, or for inference.\n",
    "    \"\"\"\n",
    "    checkpoint = torch.load(file_pth)\n",
    "    model = checkpoint[\"model\"]\n",
    "    model.load_state_dict(checkpoint[\"model_state\"])\n",
    "    optimizer = checkpoint[\"optimizer_state\"]\n",
    "    prev_epochs = checkpoint[\"epoch\"]\n",
    "    \n",
    "    return model, prev_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cb8810d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the metrics  \n",
    "def get_metrics(predicted, observed):\n",
    "    if len(predicted) == len (observed):\n",
    "        nse = 1-(np.sum(np.square(predicted - observed))/np.sum(np.square(observed - np.mean(observed))))\n",
    "        mse = 1/len(predicted)*np.sum(np.square(observed-predicted))\n",
    "        rmse = np.sqrt(mse)\n",
    "        ss_res=np.square(np.sum((observed-np.mean(observed))*(predicted-np.mean(predicted))))\n",
    "        print (ss_res)\n",
    "        ss_tot=np.sum(np.square(observed-np.mean(observed)))*np.sum(np.square(predicted-np.mean(predicted)))  \n",
    "        print (ss_tot)\n",
    "        r2 = ss_res/ss_tot\n",
    "        mae = np.sum(np.absolute(predicted-observed))/len(predicted)\n",
    "        metrics = {\"MSE\": mse, \"RMSE\":rmse, \"NSE\":nse, \"R2\":r2, \"MAE\":mae}\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "450b95e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot the loss during training\n",
    "def plot_loss(epochs, train_loss, test_loss):\n",
    "    plt.figure(figsize=[12., 6.])\n",
    "    plt.plot(epochs, train_loss, label = \"Training Loss\")\n",
    "    plt.plot(epochs, test_loss, label = \"Validation Loss\")\n",
    "    plt.title('Loss vs Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f686033",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0ac7149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(model, train_loader_b, valid_loader_b, train_loader_w, valid_loader_w, prev_epochs = 0, num_epochs = 5,\n",
    "                  num_batches = 64, learning_rate = 0.001, device = \"cpu\"):\n",
    "    \"\"\"Trains the model and compztes the average accuracy for train and tesat data.\"\"\"\n",
    "    print(\"Get data ready...\")\n",
    "    print (\"The model was trained for {} epochs, and will be trained for {} new epochs.\".format(prev_epochs, num_epochs))\n",
    "    # get number of new epochs to train for\n",
    "    new_epochs = prev_epochs + num_epochs\n",
    "    \n",
    "    # Create Criterion and Optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adamax(model.parameters(), lr = learning_rate)\n",
    "    \n",
    "    print (\"Training started...\")\n",
    "    # Train the data multiple times\n",
    "    \n",
    "    loss_vals_train = []\n",
    "    loss_vals_test = []\n",
    "    epoch = 0\n",
    "    for epoch in progress_bar(range(prev_epochs, new_epochs)):\n",
    "        train_loss = 0\n",
    "        test_loss = 0\n",
    "        print (\"Epoch {}/{}\".format(epoch+1, new_epochs))\n",
    "        print (\"-\" * 20)\n",
    "        \n",
    "        # Set the model to training mode\n",
    "        model.train()\n",
    "        model.to(device)\n",
    "        \n",
    "        for k, (x_b, y_b) in enumerate(train_loader_b): # k je iteracija -- > if k % 1 == 0: print ....\n",
    "            for j, x_w in enumerate(train_loader_w):\n",
    "                x_b, y_b = x_b.to(device), y_b.to(device)\n",
    "                x_w = x_w.to(device)\n",
    "\n",
    "                # geting the outputs of the network\n",
    "                out = model(x_w, x_b)\n",
    "\n",
    "                # Clear the gradients from the prviuos iteration\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Compute the loss\n",
    "                loss = criterion(out, y_b)\n",
    "\n",
    "                # Compute the gradients for the neurons\n",
    "                loss.backward()\n",
    "                # Save Loss after each iteration\n",
    "                train_loss += loss.item()\n",
    "                # Update the weights\n",
    "                optimizer.step()\n",
    "\n",
    "        loss_vals_train.append(train_loss/len(train_loader_b))\n",
    "        # Print Loss per training epoch   \n",
    "        print(\"TRAIN | MSE: {:.3f} | RMSE: {:.3f}\".format(train_loss/k, sqrt(train_loss/k)))\n",
    "\n",
    "        # Put the model into evaluation mode\n",
    "        model.eval()\n",
    "\n",
    "        for k, (x_b, y_b) in enumerate(valid_loader_b):\n",
    "            for j, x_w in enumerate(valid_loader_w):\n",
    "                x_b, y_b = x_b.to(device), y_b.to(device)\n",
    "                x_w = x_w.to(device)\n",
    "                # getiong the outputs of the network\n",
    "                out = model(x_w, x_b)\n",
    "                # Compute the loss\n",
    "                loss = criterion(out, y_b)\n",
    "                test_loss += loss.item()\n",
    "\n",
    "\n",
    "\n",
    "        loss_vals_test.append(test_loss/len(valid_loader_b))\n",
    "        print(\"TEST | MSE: {:.3f} | RMSE: {:.3f}\".format(test_loss/k, sqrt(test_loss/k)))\n",
    "\n",
    "\n",
    "    plot_loss(range(prev_epochs, new_epochs), loss_vals_train, loss_vals_test)\n",
    "\n",
    "    checkpoint = {\"model\": model,\n",
    "                  \"epoch\": epoch+1,\n",
    "                  \"model_state\": model.state_dict(),\n",
    "                  \"optimizer_state\": optimizer.state_dict(),\n",
    "                 }\n",
    "\n",
    "    return checkpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "794ce476",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_size_lstm = 2\n",
    "hidden_size_lstm = 120\n",
    "num_layers_lstm = 2\n",
    "device = \"cuda\"\n",
    "input_size_b = 8\n",
    "save_dir = \"clay_model_1.8.pth\"\n",
    "num_epochs = 50\n",
    "num_batches = 2\n",
    "learning_rate = 0.000025\n",
    "\n",
    "torch.manual_seed(14)\n",
    "random.seed(14)\n",
    "np.random.seed(14)\n",
    "\n",
    "if os.path.exists(save_dir):\n",
    "    clay_nn = Clay_NN(input_size_lstm, hidden_size_lstm, num_layers_lstm, device, input_size_b, )\n",
    "    clay_nn, prev_epochs = model_loader(save_dir)\n",
    "else:\n",
    "    clay_nn = Clay_NN(input_size_lstm, hidden_size_lstm, num_layers_lstm, device, input_size_b, )\n",
    "    prev_epochs = 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c8b6cdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get data ready...\n",
      "The model was trained for 0 epochs, and will be trained for 50 new epochs.\n",
      "Training started...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='50' class='' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [50/50 16:30<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "--------------------\n",
      "TRAIN | MSE: 26.659 | RMSE: 5.163\n",
      "TEST | MSE: 5.390 | RMSE: 2.322\n",
      "Epoch 2/50\n",
      "--------------------\n",
      "TRAIN | MSE: 26.316 | RMSE: 5.130\n",
      "TEST | MSE: 5.358 | RMSE: 2.315\n",
      "Epoch 3/50\n",
      "--------------------\n",
      "TRAIN | MSE: 26.021 | RMSE: 5.101\n",
      "TEST | MSE: 5.327 | RMSE: 2.308\n",
      "Epoch 4/50\n",
      "--------------------\n",
      "TRAIN | MSE: 25.720 | RMSE: 5.072\n",
      "TEST | MSE: 5.293 | RMSE: 2.301\n",
      "Epoch 5/50\n",
      "--------------------\n",
      "TRAIN | MSE: 25.390 | RMSE: 5.039\n",
      "TEST | MSE: 5.259 | RMSE: 2.293\n",
      "Epoch 6/50\n",
      "--------------------\n",
      "TRAIN | MSE: 25.062 | RMSE: 5.006\n",
      "TEST | MSE: 5.219 | RMSE: 2.284\n",
      "Epoch 7/50\n",
      "--------------------\n",
      "TRAIN | MSE: 24.744 | RMSE: 4.974\n",
      "TEST | MSE: 5.174 | RMSE: 2.275\n",
      "Epoch 8/50\n",
      "--------------------\n",
      "TRAIN | MSE: 24.434 | RMSE: 4.943\n",
      "TEST | MSE: 5.128 | RMSE: 2.264\n",
      "Epoch 9/50\n",
      "--------------------\n",
      "TRAIN | MSE: 24.118 | RMSE: 4.911\n",
      "TEST | MSE: 5.082 | RMSE: 2.254\n",
      "Epoch 10/50\n",
      "--------------------\n",
      "TRAIN | MSE: 23.804 | RMSE: 4.879\n",
      "TEST | MSE: 5.033 | RMSE: 2.243\n",
      "Epoch 11/50\n",
      "--------------------\n",
      "TRAIN | MSE: 23.476 | RMSE: 4.845\n",
      "TEST | MSE: 4.984 | RMSE: 2.233\n",
      "Epoch 12/50\n",
      "--------------------\n",
      "TRAIN | MSE: 23.148 | RMSE: 4.811\n",
      "TEST | MSE: 4.935 | RMSE: 2.221\n",
      "Epoch 13/50\n",
      "--------------------\n",
      "TRAIN | MSE: 22.830 | RMSE: 4.778\n",
      "TEST | MSE: 4.887 | RMSE: 2.211\n",
      "Epoch 14/50\n",
      "--------------------\n",
      "TRAIN | MSE: 22.527 | RMSE: 4.746\n",
      "TEST | MSE: 4.840 | RMSE: 2.200\n",
      "Epoch 15/50\n",
      "--------------------\n",
      "TRAIN | MSE: 22.225 | RMSE: 4.714\n",
      "TEST | MSE: 4.793 | RMSE: 2.189\n",
      "Epoch 16/50\n",
      "--------------------\n",
      "TRAIN | MSE: 21.922 | RMSE: 4.682\n",
      "TEST | MSE: 4.746 | RMSE: 2.179\n",
      "Epoch 17/50\n",
      "--------------------\n",
      "TRAIN | MSE: 21.615 | RMSE: 4.649\n",
      "TEST | MSE: 4.700 | RMSE: 2.168\n",
      "Epoch 18/50\n",
      "--------------------\n",
      "TRAIN | MSE: 21.307 | RMSE: 4.616\n",
      "TEST | MSE: 4.653 | RMSE: 2.157\n",
      "Epoch 19/50\n",
      "--------------------\n",
      "TRAIN | MSE: 20.999 | RMSE: 4.582\n",
      "TEST | MSE: 4.607 | RMSE: 2.146\n",
      "Epoch 20/50\n",
      "--------------------\n",
      "TRAIN | MSE: 20.692 | RMSE: 4.549\n",
      "TEST | MSE: 4.563 | RMSE: 2.136\n",
      "Epoch 21/50\n",
      "--------------------\n",
      "TRAIN | MSE: 20.385 | RMSE: 4.515\n",
      "TEST | MSE: 4.519 | RMSE: 2.126\n",
      "Epoch 22/50\n",
      "--------------------\n",
      "TRAIN | MSE: 20.073 | RMSE: 4.480\n",
      "TEST | MSE: 4.471 | RMSE: 2.115\n",
      "Epoch 23/50\n",
      "--------------------\n",
      "TRAIN | MSE: 19.729 | RMSE: 4.442\n",
      "TEST | MSE: 4.420 | RMSE: 2.102\n",
      "Epoch 24/50\n",
      "--------------------\n",
      "TRAIN | MSE: 19.366 | RMSE: 4.401\n",
      "TEST | MSE: 4.368 | RMSE: 2.090\n",
      "Epoch 25/50\n",
      "--------------------\n",
      "TRAIN | MSE: 19.007 | RMSE: 4.360\n",
      "TEST | MSE: 4.317 | RMSE: 2.078\n",
      "Epoch 26/50\n",
      "--------------------\n",
      "TRAIN | MSE: 18.649 | RMSE: 4.319\n",
      "TEST | MSE: 4.267 | RMSE: 2.066\n",
      "Epoch 27/50\n",
      "--------------------\n",
      "TRAIN | MSE: 18.294 | RMSE: 4.277\n",
      "TEST | MSE: 4.217 | RMSE: 2.054\n",
      "Epoch 28/50\n",
      "--------------------\n",
      "TRAIN | MSE: 17.943 | RMSE: 4.236\n",
      "TEST | MSE: 4.168 | RMSE: 2.041\n",
      "Epoch 29/50\n",
      "--------------------\n",
      "TRAIN | MSE: 17.591 | RMSE: 4.194\n",
      "TEST | MSE: 4.119 | RMSE: 2.030\n",
      "Epoch 30/50\n",
      "--------------------\n",
      "TRAIN | MSE: 17.238 | RMSE: 4.152\n",
      "TEST | MSE: 4.072 | RMSE: 2.018\n",
      "Epoch 31/50\n",
      "--------------------\n",
      "TRAIN | MSE: 16.884 | RMSE: 4.109\n",
      "TEST | MSE: 4.026 | RMSE: 2.006\n",
      "Epoch 32/50\n",
      "--------------------\n",
      "TRAIN | MSE: 16.535 | RMSE: 4.066\n",
      "TEST | MSE: 3.976 | RMSE: 1.994\n",
      "Epoch 33/50\n",
      "--------------------\n",
      "TRAIN | MSE: 16.187 | RMSE: 4.023\n",
      "TEST | MSE: 3.927 | RMSE: 1.982\n",
      "Epoch 34/50\n",
      "--------------------\n",
      "TRAIN | MSE: 15.842 | RMSE: 3.980\n",
      "TEST | MSE: 3.879 | RMSE: 1.970\n",
      "Epoch 35/50\n",
      "--------------------\n",
      "TRAIN | MSE: 15.505 | RMSE: 3.938\n",
      "TEST | MSE: 3.831 | RMSE: 1.957\n",
      "Epoch 36/50\n",
      "--------------------\n",
      "TRAIN | MSE: 15.172 | RMSE: 3.895\n",
      "TEST | MSE: 3.783 | RMSE: 1.945\n",
      "Epoch 37/50\n",
      "--------------------\n",
      "TRAIN | MSE: 14.843 | RMSE: 3.853\n",
      "TEST | MSE: 3.737 | RMSE: 1.933\n",
      "Epoch 38/50\n",
      "--------------------\n",
      "TRAIN | MSE: 14.516 | RMSE: 3.810\n",
      "TEST | MSE: 3.692 | RMSE: 1.921\n",
      "Epoch 39/50\n",
      "--------------------\n",
      "TRAIN | MSE: 14.194 | RMSE: 3.767\n",
      "TEST | MSE: 3.648 | RMSE: 1.910\n",
      "Epoch 40/50\n",
      "--------------------\n",
      "TRAIN | MSE: 13.875 | RMSE: 3.725\n",
      "TEST | MSE: 3.605 | RMSE: 1.899\n",
      "Epoch 41/50\n",
      "--------------------\n",
      "TRAIN | MSE: 13.561 | RMSE: 3.682\n",
      "TEST | MSE: 3.564 | RMSE: 1.888\n",
      "Epoch 42/50\n",
      "--------------------\n",
      "TRAIN | MSE: 13.251 | RMSE: 3.640\n",
      "TEST | MSE: 3.522 | RMSE: 1.877\n",
      "Epoch 43/50\n",
      "--------------------\n",
      "TRAIN | MSE: 12.946 | RMSE: 3.598\n",
      "TEST | MSE: 3.480 | RMSE: 1.866\n",
      "Epoch 44/50\n",
      "--------------------\n",
      "TRAIN | MSE: 12.647 | RMSE: 3.556\n",
      "TEST | MSE: 3.440 | RMSE: 1.855\n",
      "Epoch 45/50\n",
      "--------------------\n",
      "TRAIN | MSE: 12.354 | RMSE: 3.515\n",
      "TEST | MSE: 3.402 | RMSE: 1.844\n",
      "Epoch 46/50\n",
      "--------------------\n",
      "TRAIN | MSE: 12.066 | RMSE: 3.474\n",
      "TEST | MSE: 3.364 | RMSE: 1.834\n",
      "Epoch 47/50\n",
      "--------------------\n",
      "TRAIN | MSE: 11.784 | RMSE: 3.433\n",
      "TEST | MSE: 3.328 | RMSE: 1.824\n",
      "Epoch 48/50\n",
      "--------------------\n",
      "TRAIN | MSE: 11.509 | RMSE: 3.393\n",
      "TEST | MSE: 3.294 | RMSE: 1.815\n",
      "Epoch 49/50\n",
      "--------------------\n",
      "TRAIN | MSE: 11.241 | RMSE: 3.353\n",
      "TEST | MSE: 3.261 | RMSE: 1.806\n",
      "Epoch 50/50\n",
      "--------------------\n",
      "TRAIN | MSE: 10.979 | RMSE: 3.313\n",
      "TEST | MSE: 3.230 | RMSE: 1.797\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "checkpoint = train_network(clay_nn, train_loader_b, valid_loader_b, train_loader_w, valid_loader_w, \n",
    "                           prev_epochs=prev_epochs, num_epochs=num_epochs, \n",
    "                           num_batches= num_batches, learning_rate = learning_rate, device = device);\n",
    "\n",
    "save_model(checkpoint, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "020466a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(test_w_ds, test_b_ds, model, b_scaler):\n",
    "    clay_nn.to(\"cpu\")\n",
    "    clay_nn.eval()\n",
    "    predicted_list = list()\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(test_b_ds)):\n",
    "            item_w = test_w_ds[i].view(1,-1, 2)\n",
    "            item_b = test_b_ds[i][0].view(1, -1)\n",
    "            predicted = clay_nn(item_w, item_b).cpu()\n",
    "            predicted_list.append(b_scaler.inverse_transform(predicted))\n",
    "            \n",
    "    # converting tensor to arrays\n",
    "    results_df = pd.DataFrame(np.array(predicted_list).reshape(-1,2), columns = [\"ECM_pred\", \"Stemming_len_pred\"])\n",
    "    # deti da provjerava broj columnsa, koliko je broj predviđenih varijabli\n",
    "    #results_df[\"predicted\"]= predicted_list\n",
    "\n",
    "\n",
    "    #observed = b_scaler.inverse_transform(observed_data.numpy()[:,0])      \n",
    "    # plot simple line chart\n",
    "    #plot_results(observed[:], predicted[:])\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea531bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_test = make_prediction(test_w_ds, test_b_ds, clay_nn, b_scaler) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1336c534",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_valid = make_prediction(valid_w_ds, valid_b_ds, clay_nn, b_scaler) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56d0e986",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_train = make_prediction(train_w_ds, train_b_ds, clay_nn, b_scaler) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2201bd35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ECM_pred</th>\n",
       "      <th>Stemming_len_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.996004</td>\n",
       "      <td>0.750762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.384665</td>\n",
       "      <td>0.616259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.484148</td>\n",
       "      <td>0.628634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.614332</td>\n",
       "      <td>0.780500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.446466</td>\n",
       "      <td>0.800873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.471013</td>\n",
       "      <td>0.621214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ECM_pred  Stemming_len_pred\n",
       "0  0.996004           0.750762\n",
       "1  0.384665           0.616259\n",
       "2  0.484148           0.628634\n",
       "3  0.614332           0.780500\n",
       "4  0.446466           0.800873\n",
       "5  0.471013           0.621214"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1fd321eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ECM_pred</th>\n",
       "      <th>Stemming_len_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.155923</td>\n",
       "      <td>0.719262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.489050</td>\n",
       "      <td>0.631402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.547654</td>\n",
       "      <td>0.664505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.632930</td>\n",
       "      <td>0.692035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.924716</td>\n",
       "      <td>0.723989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.231544</td>\n",
       "      <td>0.595249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.407117</td>\n",
       "      <td>0.625693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.742295</td>\n",
       "      <td>0.770532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.739280</td>\n",
       "      <td>0.742086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.744252</td>\n",
       "      <td>0.730724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.637583</td>\n",
       "      <td>0.741733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ECM_pred  Stemming_len_pred\n",
       "0   0.155923           0.719262\n",
       "1   0.489050           0.631402\n",
       "2   0.547654           0.664505\n",
       "3   0.632930           0.692035\n",
       "4   0.924716           0.723989\n",
       "5   0.231544           0.595249\n",
       "6   0.407117           0.625693\n",
       "7   0.742295           0.770532\n",
       "8   0.739280           0.742086\n",
       "9   0.744252           0.730724\n",
       "10  0.637583           0.741733"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f0c4186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ECM_pred</th>\n",
       "      <th>Stemming_len_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.844464</td>\n",
       "      <td>0.840347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.474802</td>\n",
       "      <td>0.740055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.806237</td>\n",
       "      <td>0.810605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.676966</td>\n",
       "      <td>0.788942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.599271</td>\n",
       "      <td>0.774474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.479474</td>\n",
       "      <td>0.839738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.369971</td>\n",
       "      <td>0.767135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.484322</td>\n",
       "      <td>0.829676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.729481</td>\n",
       "      <td>0.807714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.871328</td>\n",
       "      <td>0.813296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.335836</td>\n",
       "      <td>0.573912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.363161</td>\n",
       "      <td>0.560294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.483897</td>\n",
       "      <td>0.628492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.469829</td>\n",
       "      <td>0.620546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.734394</td>\n",
       "      <td>0.703147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.642922</td>\n",
       "      <td>0.689618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.676275</td>\n",
       "      <td>0.696782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.923217</td>\n",
       "      <td>0.723825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.508081</td>\n",
       "      <td>0.642152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.239471</td>\n",
       "      <td>0.630654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.690123</td>\n",
       "      <td>0.729981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.682766</td>\n",
       "      <td>0.748020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.688208</td>\n",
       "      <td>0.739028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.703169</td>\n",
       "      <td>0.702282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.439044</td>\n",
       "      <td>0.610703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.275515</td>\n",
       "      <td>0.588445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.268555</td>\n",
       "      <td>0.623933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ECM_pred  Stemming_len_pred\n",
       "0   0.844464           0.840347\n",
       "1   0.474802           0.740055\n",
       "2   0.806237           0.810605\n",
       "3   0.676966           0.788942\n",
       "4   0.599271           0.774474\n",
       "5   0.479474           0.839738\n",
       "6   0.369971           0.767135\n",
       "7   0.484322           0.829676\n",
       "8   0.729481           0.807714\n",
       "9   0.871328           0.813296\n",
       "10  0.335836           0.573912\n",
       "11  0.363161           0.560294\n",
       "12  0.483897           0.628492\n",
       "13  0.469829           0.620546\n",
       "14  0.734394           0.703147\n",
       "15  0.642922           0.689618\n",
       "16  0.676275           0.696782\n",
       "17  0.923217           0.723825\n",
       "18  0.508081           0.642152\n",
       "19  0.239471           0.630654\n",
       "20  0.690123           0.729981\n",
       "21  0.682766           0.748020\n",
       "22  0.688208           0.739028\n",
       "23  0.703169           0.702282\n",
       "24  0.439044           0.610703\n",
       "25  0.275515           0.588445\n",
       "26  0.268555           0.623933"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e48beeef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ECM_pred</th>\n",
       "      <th>Stemming_len_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.996004</td>\n",
       "      <td>0.750762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.384665</td>\n",
       "      <td>0.616259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.484148</td>\n",
       "      <td>0.628634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.614332</td>\n",
       "      <td>0.780500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.446466</td>\n",
       "      <td>0.800873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.471013</td>\n",
       "      <td>0.621214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.155923</td>\n",
       "      <td>0.719262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.489050</td>\n",
       "      <td>0.631402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.547654</td>\n",
       "      <td>0.664505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.632930</td>\n",
       "      <td>0.692035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.924716</td>\n",
       "      <td>0.723989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.231544</td>\n",
       "      <td>0.595249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.407117</td>\n",
       "      <td>0.625693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.742295</td>\n",
       "      <td>0.770532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.739280</td>\n",
       "      <td>0.742086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.744252</td>\n",
       "      <td>0.730724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.637583</td>\n",
       "      <td>0.741733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.844464</td>\n",
       "      <td>0.840347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.474802</td>\n",
       "      <td>0.740055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.806237</td>\n",
       "      <td>0.810605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.676966</td>\n",
       "      <td>0.788942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.599271</td>\n",
       "      <td>0.774474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.479474</td>\n",
       "      <td>0.839738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.369971</td>\n",
       "      <td>0.767135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.484322</td>\n",
       "      <td>0.829676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.729481</td>\n",
       "      <td>0.807714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.871328</td>\n",
       "      <td>0.813296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.335836</td>\n",
       "      <td>0.573912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.363161</td>\n",
       "      <td>0.560294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.483897</td>\n",
       "      <td>0.628492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.469829</td>\n",
       "      <td>0.620546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.734394</td>\n",
       "      <td>0.703147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.642922</td>\n",
       "      <td>0.689618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.676275</td>\n",
       "      <td>0.696782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.923217</td>\n",
       "      <td>0.723825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.508081</td>\n",
       "      <td>0.642152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.239471</td>\n",
       "      <td>0.630654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.690123</td>\n",
       "      <td>0.729981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.682766</td>\n",
       "      <td>0.748020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.688208</td>\n",
       "      <td>0.739028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.703169</td>\n",
       "      <td>0.702282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.439044</td>\n",
       "      <td>0.610703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.275515</td>\n",
       "      <td>0.588445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.268555</td>\n",
       "      <td>0.623933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ECM_pred  Stemming_len_pred\n",
       "0   0.996004           0.750762\n",
       "1   0.384665           0.616259\n",
       "2   0.484148           0.628634\n",
       "3   0.614332           0.780500\n",
       "4   0.446466           0.800873\n",
       "5   0.471013           0.621214\n",
       "0   0.155923           0.719262\n",
       "1   0.489050           0.631402\n",
       "2   0.547654           0.664505\n",
       "3   0.632930           0.692035\n",
       "4   0.924716           0.723989\n",
       "5   0.231544           0.595249\n",
       "6   0.407117           0.625693\n",
       "7   0.742295           0.770532\n",
       "8   0.739280           0.742086\n",
       "9   0.744252           0.730724\n",
       "10  0.637583           0.741733\n",
       "0   0.844464           0.840347\n",
       "1   0.474802           0.740055\n",
       "2   0.806237           0.810605\n",
       "3   0.676966           0.788942\n",
       "4   0.599271           0.774474\n",
       "5   0.479474           0.839738\n",
       "6   0.369971           0.767135\n",
       "7   0.484322           0.829676\n",
       "8   0.729481           0.807714\n",
       "9   0.871328           0.813296\n",
       "10  0.335836           0.573912\n",
       "11  0.363161           0.560294\n",
       "12  0.483897           0.628492\n",
       "13  0.469829           0.620546\n",
       "14  0.734394           0.703147\n",
       "15  0.642922           0.689618\n",
       "16  0.676275           0.696782\n",
       "17  0.923217           0.723825\n",
       "18  0.508081           0.642152\n",
       "19  0.239471           0.630654\n",
       "20  0.690123           0.729981\n",
       "21  0.682766           0.748020\n",
       "22  0.688208           0.739028\n",
       "23  0.703169           0.702282\n",
       "24  0.439044           0.610703\n",
       "25  0.275515           0.588445\n",
       "26  0.268555           0.623933"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_data_df = pd.concat([results_df_valid, results_df_test, results_df_train], axis = 0)\n",
    "predicted_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fde5327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe576b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859ff5d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff38fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c8d0fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795e0b36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24c25680",
   "metadata": {},
   "source": [
    "## Creating data for visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002bf863",
   "metadata": {},
   "source": [
    "### Blasting data - observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4efb5e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Explosive\\nCharge Mass</th>\n",
       "      <th>Stemming Length</th>\n",
       "      <th>Borehole Depth</th>\n",
       "      <th>Dubina minske bušotine nakon miniranja</th>\n",
       "      <th>Volumen nastalog proširenja</th>\n",
       "      <th>Volumen cijele minske bušotine</th>\n",
       "      <th>Volumen nastalog proširenja.1</th>\n",
       "      <th>Volumen cijele minske bušotine.1</th>\n",
       "      <th>Produbljenje</th>\n",
       "      <th>Proširenje</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-06-12</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.07</td>\n",
       "      <td>3.58</td>\n",
       "      <td>807.00</td>\n",
       "      <td>844.50</td>\n",
       "      <td>0.80700</td>\n",
       "      <td>0.84450</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1.169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-06-12</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.30</td>\n",
       "      <td>3.04</td>\n",
       "      <td>3.20</td>\n",
       "      <td>80.50</td>\n",
       "      <td>111.50</td>\n",
       "      <td>0.08050</td>\n",
       "      <td>0.11150</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-06-12</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.30</td>\n",
       "      <td>3.05</td>\n",
       "      <td>3.28</td>\n",
       "      <td>154.50</td>\n",
       "      <td>188.00</td>\n",
       "      <td>0.15450</td>\n",
       "      <td>0.18800</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-06-12</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.87</td>\n",
       "      <td>3.20</td>\n",
       "      <td>393.50</td>\n",
       "      <td>417.40</td>\n",
       "      <td>0.39350</td>\n",
       "      <td>0.41740</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-06-12</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.05</td>\n",
       "      <td>255.50</td>\n",
       "      <td>281.00</td>\n",
       "      <td>0.25550</td>\n",
       "      <td>0.28100</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-06-12</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3.07</td>\n",
       "      <td>3.30</td>\n",
       "      <td>113.50</td>\n",
       "      <td>151.00</td>\n",
       "      <td>0.11350</td>\n",
       "      <td>0.15100</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.05</td>\n",
       "      <td>2.30</td>\n",
       "      <td>117.50</td>\n",
       "      <td>138.00</td>\n",
       "      <td>0.11750</td>\n",
       "      <td>0.13800</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.50</td>\n",
       "      <td>298.00</td>\n",
       "      <td>317.50</td>\n",
       "      <td>0.29800</td>\n",
       "      <td>0.31750</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.50</td>\n",
       "      <td>378.50</td>\n",
       "      <td>399.00</td>\n",
       "      <td>0.37850</td>\n",
       "      <td>0.39900</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.50</td>\n",
       "      <td>519.00</td>\n",
       "      <td>542.00</td>\n",
       "      <td>0.51900</td>\n",
       "      <td>0.54200</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.70</td>\n",
       "      <td>809.50</td>\n",
       "      <td>822.50</td>\n",
       "      <td>0.80950</td>\n",
       "      <td>0.82250</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.30</td>\n",
       "      <td>148.00</td>\n",
       "      <td>166.50</td>\n",
       "      <td>0.14800</td>\n",
       "      <td>0.16650</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.40</td>\n",
       "      <td>281.50</td>\n",
       "      <td>299.50</td>\n",
       "      <td>0.28150</td>\n",
       "      <td>0.29950</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.48</td>\n",
       "      <td>769.50</td>\n",
       "      <td>787.00</td>\n",
       "      <td>0.76950</td>\n",
       "      <td>0.78700</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.50</td>\n",
       "      <td>740.50</td>\n",
       "      <td>756.00</td>\n",
       "      <td>0.74050</td>\n",
       "      <td>0.75600</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.52</td>\n",
       "      <td>722.70</td>\n",
       "      <td>735.00</td>\n",
       "      <td>0.72270</td>\n",
       "      <td>0.73500</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.45</td>\n",
       "      <td>615.05</td>\n",
       "      <td>631.05</td>\n",
       "      <td>0.61505</td>\n",
       "      <td>0.63105</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Explosive\\nCharge Mass  Stemming Length  Borehole Depth  \\\n",
       "0  2015-06-12                     1.6             1.00            3.07   \n",
       "1  2015-06-12                     0.2             0.30            3.04   \n",
       "2  2015-06-12                     0.4             0.30            3.05   \n",
       "3  2015-06-12                     0.8             0.50            2.87   \n",
       "4  2015-06-12                     0.6             0.50            2.80   \n",
       "5  2015-06-12                     0.4             0.50            3.07   \n",
       "0  2016-08-31                     0.2             0.50            2.05   \n",
       "1  2016-08-31                     0.4             0.50            2.10   \n",
       "2  2016-08-31                     0.6             0.50            2.10   \n",
       "3  2016-08-31                     0.8             0.50            2.10   \n",
       "4  2016-08-31                     1.0             0.50            2.10   \n",
       "5  2016-08-31                     0.2             0.50            2.10   \n",
       "6  2016-08-31                     0.4             0.50            2.10   \n",
       "7  2016-08-31                     0.6             0.32            2.10   \n",
       "8  2016-08-31                     0.8             0.50            2.10   \n",
       "9  2016-08-31                     0.8             0.50            2.10   \n",
       "10 2016-08-31                     0.6             0.50            2.10   \n",
       "\n",
       "    Dubina minske bušotine nakon miniranja  Volumen nastalog proširenja  \\\n",
       "0                                     3.58                       807.00   \n",
       "1                                     3.20                        80.50   \n",
       "2                                     3.28                       154.50   \n",
       "3                                     3.20                       393.50   \n",
       "4                                     3.05                       255.50   \n",
       "5                                     3.30                       113.50   \n",
       "0                                     2.30                       117.50   \n",
       "1                                     2.50                       298.00   \n",
       "2                                     2.50                       378.50   \n",
       "3                                     2.50                       519.00   \n",
       "4                                     2.70                       809.50   \n",
       "5                                     2.30                       148.00   \n",
       "6                                     2.40                       281.50   \n",
       "7                                     2.48                       769.50   \n",
       "8                                     2.50                       740.50   \n",
       "9                                     2.52                       722.70   \n",
       "10                                    2.45                       615.05   \n",
       "\n",
       "    Volumen cijele minske bušotine  Volumen nastalog proširenja.1  \\\n",
       "0                           844.50                        0.80700   \n",
       "1                           111.50                        0.08050   \n",
       "2                           188.00                        0.15450   \n",
       "3                           417.40                        0.39350   \n",
       "4                           281.00                        0.25550   \n",
       "5                           151.00                        0.11350   \n",
       "0                           138.00                        0.11750   \n",
       "1                           317.50                        0.29800   \n",
       "2                           399.00                        0.37850   \n",
       "3                           542.00                        0.51900   \n",
       "4                           822.50                        0.80950   \n",
       "5                           166.50                        0.14800   \n",
       "6                           299.50                        0.28150   \n",
       "7                           787.00                        0.76950   \n",
       "8                           756.00                        0.74050   \n",
       "9                           735.00                        0.72270   \n",
       "10                          631.05                        0.61505   \n",
       "\n",
       "    Volumen cijele minske bušotine.1  Produbljenje  Proširenje  \n",
       "0                            0.84450          0.51       1.169  \n",
       "1                            0.11150          0.16       0.584  \n",
       "2                            0.18800          0.23       0.670  \n",
       "3                            0.41740          0.33       0.953  \n",
       "4                            0.28100          0.25       0.783  \n",
       "5                            0.15100          0.23       0.693  \n",
       "0                            0.13800          0.25       0.601  \n",
       "1                            0.31750          0.40       0.848  \n",
       "2                            0.39900          0.40       1.088  \n",
       "3                            0.54200          0.40       1.060  \n",
       "4                            0.82250          0.60       1.111  \n",
       "5                            0.16650          0.20       0.662  \n",
       "6                            0.29950          0.30       0.866  \n",
       "7                            0.78700          0.38       1.238  \n",
       "8                            0.75600          0.40       1.070  \n",
       "9                            0.73500          0.42       1.071  \n",
       "10                           0.63105          0.35       1.152  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_blasting = df_b.loc[df_b[\"Date\"] == \"2016-08-31\"].reset_index().iloc[:, 1:]\n",
    "\n",
    "valid_data_blasting = df_b.loc[df_b[\"Date\"] == \"2015-06-12\"].reset_index().iloc[:, 1:]\n",
    "\n",
    "train_data_blasting = df_b.loc[(df_b[\"Date\"] == \"2014-06-12\")].reset_index().iloc[:, 1:]\n",
    "\n",
    "observed_data_df = pd.concat([valid_data_blasting, test_data_blasting, train_data_blasting], axis = 0)\n",
    "\n",
    "observed_data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4092cf72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Explosive\\nCharge Mass</th>\n",
       "      <th>Stemming Length</th>\n",
       "      <th>Borehole Depth</th>\n",
       "      <th>Dubina minske bušotine nakon miniranja</th>\n",
       "      <th>Volumen nastalog proširenja</th>\n",
       "      <th>Volumen cijele minske bušotine</th>\n",
       "      <th>Volumen nastalog proširenja.1</th>\n",
       "      <th>Volumen cijele minske bušotine.1</th>\n",
       "      <th>Produbljenje</th>\n",
       "      <th>Proširenje</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-12-06</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.03</td>\n",
       "      <td>2.43</td>\n",
       "      <td>872.20</td>\n",
       "      <td>883.80</td>\n",
       "      <td>0.87220</td>\n",
       "      <td>0.88380</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-12-06</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.09</td>\n",
       "      <td>2.36</td>\n",
       "      <td>371.65</td>\n",
       "      <td>395.20</td>\n",
       "      <td>0.37165</td>\n",
       "      <td>0.39520</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-12-06</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.01</td>\n",
       "      <td>2.44</td>\n",
       "      <td>751.65</td>\n",
       "      <td>758.90</td>\n",
       "      <td>0.75165</td>\n",
       "      <td>0.75890</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-12-06</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.98</td>\n",
       "      <td>2.38</td>\n",
       "      <td>574.70</td>\n",
       "      <td>589.20</td>\n",
       "      <td>0.57470</td>\n",
       "      <td>0.58920</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-12-06</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.07</td>\n",
       "      <td>2.41</td>\n",
       "      <td>507.10</td>\n",
       "      <td>523.05</td>\n",
       "      <td>0.50710</td>\n",
       "      <td>0.52305</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2014-12-06</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.94</td>\n",
       "      <td>2.23</td>\n",
       "      <td>461.55</td>\n",
       "      <td>476.55</td>\n",
       "      <td>0.46155</td>\n",
       "      <td>0.47655</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014-12-06</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.98</td>\n",
       "      <td>2.20</td>\n",
       "      <td>323.00</td>\n",
       "      <td>335.50</td>\n",
       "      <td>0.32300</td>\n",
       "      <td>0.33550</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014-12-06</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.94</td>\n",
       "      <td>2.22</td>\n",
       "      <td>436.96</td>\n",
       "      <td>454.21</td>\n",
       "      <td>0.43696</td>\n",
       "      <td>0.45421</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2014-12-06</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.94</td>\n",
       "      <td>2.36</td>\n",
       "      <td>656.95</td>\n",
       "      <td>669.20</td>\n",
       "      <td>0.65695</td>\n",
       "      <td>0.66920</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2014-12-06</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.02</td>\n",
       "      <td>2.48</td>\n",
       "      <td>835.50</td>\n",
       "      <td>849.90</td>\n",
       "      <td>0.83550</td>\n",
       "      <td>0.84990</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2016-07-20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.44</td>\n",
       "      <td>2.62</td>\n",
       "      <td>100.50</td>\n",
       "      <td>127.00</td>\n",
       "      <td>0.10050</td>\n",
       "      <td>0.12700</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2016-07-20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.52</td>\n",
       "      <td>2.74</td>\n",
       "      <td>64.50</td>\n",
       "      <td>93.00</td>\n",
       "      <td>0.06450</td>\n",
       "      <td>0.09300</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2016-07-20</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.47</td>\n",
       "      <td>2.78</td>\n",
       "      <td>244.50</td>\n",
       "      <td>264.00</td>\n",
       "      <td>0.24450</td>\n",
       "      <td>0.26400</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2016-07-20</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2.83</td>\n",
       "      <td>194.50</td>\n",
       "      <td>219.00</td>\n",
       "      <td>0.19450</td>\n",
       "      <td>0.21900</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2016-07-20</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2.85</td>\n",
       "      <td>616.00</td>\n",
       "      <td>632.00</td>\n",
       "      <td>0.61600</td>\n",
       "      <td>0.63200</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2016-07-20</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.18</td>\n",
       "      <td>2.64</td>\n",
       "      <td>344.00</td>\n",
       "      <td>363.00</td>\n",
       "      <td>0.34400</td>\n",
       "      <td>0.36300</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2016-07-20</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.68</td>\n",
       "      <td>362.60</td>\n",
       "      <td>374.75</td>\n",
       "      <td>0.36260</td>\n",
       "      <td>0.37475</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2016-07-20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.54</td>\n",
       "      <td>3.06</td>\n",
       "      <td>710.00</td>\n",
       "      <td>723.50</td>\n",
       "      <td>0.71000</td>\n",
       "      <td>0.72350</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2016-07-20</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.52</td>\n",
       "      <td>2.76</td>\n",
       "      <td>292.50</td>\n",
       "      <td>318.00</td>\n",
       "      <td>0.29250</td>\n",
       "      <td>0.31800</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2016-07-20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.16</td>\n",
       "      <td>82.50</td>\n",
       "      <td>101.50</td>\n",
       "      <td>0.08250</td>\n",
       "      <td>0.10150</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2016-07-20</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.22</td>\n",
       "      <td>2.59</td>\n",
       "      <td>527.60</td>\n",
       "      <td>543.75</td>\n",
       "      <td>0.59415</td>\n",
       "      <td>0.61140</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2016-07-20</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.26</td>\n",
       "      <td>2.57</td>\n",
       "      <td>618.40</td>\n",
       "      <td>635.70</td>\n",
       "      <td>0.61840</td>\n",
       "      <td>0.63570</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2016-07-20</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.31</td>\n",
       "      <td>2.60</td>\n",
       "      <td>633.00</td>\n",
       "      <td>681.50</td>\n",
       "      <td>0.63300</td>\n",
       "      <td>0.68150</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2016-07-20</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.34</td>\n",
       "      <td>2.70</td>\n",
       "      <td>569.00</td>\n",
       "      <td>589.50</td>\n",
       "      <td>0.56900</td>\n",
       "      <td>0.58950</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2016-07-20</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.19</td>\n",
       "      <td>2.51</td>\n",
       "      <td>216.00</td>\n",
       "      <td>231.50</td>\n",
       "      <td>0.21600</td>\n",
       "      <td>0.23150</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2016-07-20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.18</td>\n",
       "      <td>2.40</td>\n",
       "      <td>70.00</td>\n",
       "      <td>90.50</td>\n",
       "      <td>0.07000</td>\n",
       "      <td>0.09050</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2016-07-20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.01</td>\n",
       "      <td>2.25</td>\n",
       "      <td>98.00</td>\n",
       "      <td>118.50</td>\n",
       "      <td>0.09800</td>\n",
       "      <td>0.11850</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2015-06-12</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.07</td>\n",
       "      <td>3.58</td>\n",
       "      <td>807.00</td>\n",
       "      <td>844.50</td>\n",
       "      <td>0.80700</td>\n",
       "      <td>0.84450</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1.169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2015-06-12</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>3.04</td>\n",
       "      <td>3.20</td>\n",
       "      <td>80.50</td>\n",
       "      <td>111.50</td>\n",
       "      <td>0.08050</td>\n",
       "      <td>0.11150</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2015-06-12</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.30</td>\n",
       "      <td>3.05</td>\n",
       "      <td>3.28</td>\n",
       "      <td>154.50</td>\n",
       "      <td>188.00</td>\n",
       "      <td>0.15450</td>\n",
       "      <td>0.18800</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2015-06-12</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.87</td>\n",
       "      <td>3.20</td>\n",
       "      <td>393.50</td>\n",
       "      <td>417.40</td>\n",
       "      <td>0.39350</td>\n",
       "      <td>0.41740</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2015-06-12</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.05</td>\n",
       "      <td>255.50</td>\n",
       "      <td>281.00</td>\n",
       "      <td>0.25550</td>\n",
       "      <td>0.28100</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2015-06-12</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3.07</td>\n",
       "      <td>3.30</td>\n",
       "      <td>113.50</td>\n",
       "      <td>151.00</td>\n",
       "      <td>0.11350</td>\n",
       "      <td>0.15100</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.05</td>\n",
       "      <td>2.30</td>\n",
       "      <td>117.50</td>\n",
       "      <td>138.00</td>\n",
       "      <td>0.11750</td>\n",
       "      <td>0.13800</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.50</td>\n",
       "      <td>298.00</td>\n",
       "      <td>317.50</td>\n",
       "      <td>0.29800</td>\n",
       "      <td>0.31750</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.50</td>\n",
       "      <td>378.50</td>\n",
       "      <td>399.00</td>\n",
       "      <td>0.37850</td>\n",
       "      <td>0.39900</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.50</td>\n",
       "      <td>519.00</td>\n",
       "      <td>542.00</td>\n",
       "      <td>0.51900</td>\n",
       "      <td>0.54200</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.70</td>\n",
       "      <td>809.50</td>\n",
       "      <td>822.50</td>\n",
       "      <td>0.80950</td>\n",
       "      <td>0.82250</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.30</td>\n",
       "      <td>148.00</td>\n",
       "      <td>166.50</td>\n",
       "      <td>0.14800</td>\n",
       "      <td>0.16650</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.40</td>\n",
       "      <td>281.50</td>\n",
       "      <td>299.50</td>\n",
       "      <td>0.28150</td>\n",
       "      <td>0.29950</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.32</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.48</td>\n",
       "      <td>769.50</td>\n",
       "      <td>787.00</td>\n",
       "      <td>0.76950</td>\n",
       "      <td>0.78700</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.50</td>\n",
       "      <td>740.50</td>\n",
       "      <td>756.00</td>\n",
       "      <td>0.74050</td>\n",
       "      <td>0.75600</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.52</td>\n",
       "      <td>722.70</td>\n",
       "      <td>735.00</td>\n",
       "      <td>0.72270</td>\n",
       "      <td>0.73500</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.45</td>\n",
       "      <td>615.05</td>\n",
       "      <td>631.05</td>\n",
       "      <td>0.61505</td>\n",
       "      <td>0.63105</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Explosive\\nCharge Mass  Stemming Length  Borehole Depth  \\\n",
       "0  2014-12-06                    1.25             1.00            2.03   \n",
       "1  2014-12-06                    0.50             1.00            2.09   \n",
       "2  2014-12-06                    1.00             1.00            2.01   \n",
       "3  2014-12-06                    0.80             1.00            1.98   \n",
       "4  2014-12-06                    0.60             1.00            2.07   \n",
       "5  2014-12-06                    0.40             1.00            1.94   \n",
       "6  2014-12-06                    0.40             1.00            1.98   \n",
       "7  2014-12-06                    0.60             1.00            1.94   \n",
       "8  2014-12-06                    0.80             1.00            1.94   \n",
       "9  2014-12-06                    1.00             1.00            2.02   \n",
       "10 2016-07-20                    0.20             0.50            2.44   \n",
       "11 2016-07-20                    0.20             0.50            2.52   \n",
       "12 2016-07-20                    0.40             0.50            2.47   \n",
       "13 2016-07-20                    0.40             0.50            2.53   \n",
       "14 2016-07-20                    0.60             0.50            2.51   \n",
       "15 2016-07-20                    0.80             0.50            2.18   \n",
       "16 2016-07-20                    0.80             0.50            2.20   \n",
       "17 2016-07-20                    1.00             0.50            2.54   \n",
       "18 2016-07-20                    0.40             0.50            2.52   \n",
       "19 2016-07-20                    0.20             0.50            1.90   \n",
       "20 2016-07-20                    0.60             0.50            2.22   \n",
       "21 2016-07-20                    0.80             0.50            2.26   \n",
       "22 2016-07-20                    0.60             0.50            2.31   \n",
       "23 2016-07-20                    0.80             0.50            2.34   \n",
       "24 2016-07-20                    0.40             0.50            2.19   \n",
       "25 2016-07-20                    0.20             0.50            2.18   \n",
       "26 2016-07-20                    0.20             0.50            2.01   \n",
       "27 2015-06-12                    1.60             1.00            3.07   \n",
       "28 2015-06-12                    0.20             0.30            3.04   \n",
       "29 2015-06-12                    0.40             0.30            3.05   \n",
       "30 2015-06-12                    0.80             0.50            2.87   \n",
       "31 2015-06-12                    0.60             0.50            2.80   \n",
       "32 2015-06-12                    0.40             0.50            3.07   \n",
       "33 2016-08-31                    0.20             0.50            2.05   \n",
       "34 2016-08-31                    0.40             0.50            2.10   \n",
       "35 2016-08-31                    0.60             0.50            2.10   \n",
       "36 2016-08-31                    0.80             0.50            2.10   \n",
       "37 2016-08-31                    1.00             0.50            2.10   \n",
       "38 2016-08-31                    0.20             0.50            2.10   \n",
       "39 2016-08-31                    0.40             0.50            2.10   \n",
       "40 2016-08-31                    0.60             0.32            2.10   \n",
       "41 2016-08-31                    0.80             0.50            2.10   \n",
       "42 2016-08-31                    0.80             0.50            2.10   \n",
       "43 2016-08-31                    0.60             0.50            2.10   \n",
       "\n",
       "    Dubina minske bušotine nakon miniranja  Volumen nastalog proširenja  \\\n",
       "0                                     2.43                       872.20   \n",
       "1                                     2.36                       371.65   \n",
       "2                                     2.44                       751.65   \n",
       "3                                     2.38                       574.70   \n",
       "4                                     2.41                       507.10   \n",
       "5                                     2.23                       461.55   \n",
       "6                                     2.20                       323.00   \n",
       "7                                     2.22                       436.96   \n",
       "8                                     2.36                       656.95   \n",
       "9                                     2.48                       835.50   \n",
       "10                                    2.62                       100.50   \n",
       "11                                    2.74                        64.50   \n",
       "12                                    2.78                       244.50   \n",
       "13                                    2.83                       194.50   \n",
       "14                                    2.85                       616.00   \n",
       "15                                    2.64                       344.00   \n",
       "16                                    2.68                       362.60   \n",
       "17                                    3.06                       710.00   \n",
       "18                                    2.76                       292.50   \n",
       "19                                    2.16                        82.50   \n",
       "20                                    2.59                       527.60   \n",
       "21                                    2.57                       618.40   \n",
       "22                                    2.60                       633.00   \n",
       "23                                    2.70                       569.00   \n",
       "24                                    2.51                       216.00   \n",
       "25                                    2.40                        70.00   \n",
       "26                                    2.25                        98.00   \n",
       "27                                    3.58                       807.00   \n",
       "28                                    3.20                        80.50   \n",
       "29                                    3.28                       154.50   \n",
       "30                                    3.20                       393.50   \n",
       "31                                    3.05                       255.50   \n",
       "32                                    3.30                       113.50   \n",
       "33                                    2.30                       117.50   \n",
       "34                                    2.50                       298.00   \n",
       "35                                    2.50                       378.50   \n",
       "36                                    2.50                       519.00   \n",
       "37                                    2.70                       809.50   \n",
       "38                                    2.30                       148.00   \n",
       "39                                    2.40                       281.50   \n",
       "40                                    2.48                       769.50   \n",
       "41                                    2.50                       740.50   \n",
       "42                                    2.52                       722.70   \n",
       "43                                    2.45                       615.05   \n",
       "\n",
       "    Volumen cijele minske bušotine  Volumen nastalog proširenja.1  \\\n",
       "0                           883.80                        0.87220   \n",
       "1                           395.20                        0.37165   \n",
       "2                           758.90                        0.75165   \n",
       "3                           589.20                        0.57470   \n",
       "4                           523.05                        0.50710   \n",
       "5                           476.55                        0.46155   \n",
       "6                           335.50                        0.32300   \n",
       "7                           454.21                        0.43696   \n",
       "8                           669.20                        0.65695   \n",
       "9                           849.90                        0.83550   \n",
       "10                          127.00                        0.10050   \n",
       "11                           93.00                        0.06450   \n",
       "12                          264.00                        0.24450   \n",
       "13                          219.00                        0.19450   \n",
       "14                          632.00                        0.61600   \n",
       "15                          363.00                        0.34400   \n",
       "16                          374.75                        0.36260   \n",
       "17                          723.50                        0.71000   \n",
       "18                          318.00                        0.29250   \n",
       "19                          101.50                        0.08250   \n",
       "20                          543.75                        0.59415   \n",
       "21                          635.70                        0.61840   \n",
       "22                          681.50                        0.63300   \n",
       "23                          589.50                        0.56900   \n",
       "24                          231.50                        0.21600   \n",
       "25                           90.50                        0.07000   \n",
       "26                          118.50                        0.09800   \n",
       "27                          844.50                        0.80700   \n",
       "28                          111.50                        0.08050   \n",
       "29                          188.00                        0.15450   \n",
       "30                          417.40                        0.39350   \n",
       "31                          281.00                        0.25550   \n",
       "32                          151.00                        0.11350   \n",
       "33                          138.00                        0.11750   \n",
       "34                          317.50                        0.29800   \n",
       "35                          399.00                        0.37850   \n",
       "36                          542.00                        0.51900   \n",
       "37                          822.50                        0.80950   \n",
       "38                          166.50                        0.14800   \n",
       "39                          299.50                        0.28150   \n",
       "40                          787.00                        0.76950   \n",
       "41                          756.00                        0.74050   \n",
       "42                          735.00                        0.72270   \n",
       "43                          631.05                        0.61505   \n",
       "\n",
       "    Volumen cijele minske bušotine.1  Produbljenje  Proširenje  \n",
       "0                            0.88380          0.40       1.193  \n",
       "1                            0.39520          0.27       1.006  \n",
       "2                            0.75890          0.43       1.254  \n",
       "3                            0.58920          0.40       1.169  \n",
       "4                            0.52305          0.34       1.153  \n",
       "5                            0.47655          0.26       1.045  \n",
       "6                            0.33550          0.22       0.881  \n",
       "7                            0.45421          0.28       1.096  \n",
       "8                            0.66920          0.42       1.129  \n",
       "9                            0.84990          0.46       1.140  \n",
       "10                           0.12700          0.18       0.576  \n",
       "11                           0.09300          0.22       0.577  \n",
       "12                           0.26400          0.31       0.698  \n",
       "13                           0.21900          0.30       0.787  \n",
       "14                           0.63200          0.34       1.043  \n",
       "15                           0.36300          0.46       0.877  \n",
       "16                           0.37475          0.48       0.875  \n",
       "17                           0.72350          0.52       1.157  \n",
       "18                           0.31800          0.26       0.936  \n",
       "19                           0.10150          0.26       0.557  \n",
       "20                           0.61140          0.35       1.104  \n",
       "21                           0.63570          0.31       1.190  \n",
       "22                           0.68150          0.29       1.085  \n",
       "23                           0.58950          0.36       1.131  \n",
       "24                           0.23150          0.32       0.585  \n",
       "25                           0.09050          0.22       0.505  \n",
       "26                           0.11850          0.24       0.687  \n",
       "27                           0.84450          0.51       1.169  \n",
       "28                           0.11150          0.16       0.584  \n",
       "29                           0.18800          0.23       0.670  \n",
       "30                           0.41740          0.33       0.953  \n",
       "31                           0.28100          0.25       0.783  \n",
       "32                           0.15100          0.23       0.693  \n",
       "33                           0.13800          0.25       0.601  \n",
       "34                           0.31750          0.40       0.848  \n",
       "35                           0.39900          0.40       1.088  \n",
       "36                           0.54200          0.40       1.060  \n",
       "37                           0.82250          0.60       1.111  \n",
       "38                           0.16650          0.20       0.662  \n",
       "39                           0.29950          0.30       0.866  \n",
       "40                           0.78700          0.38       1.238  \n",
       "41                           0.75600          0.40       1.070  \n",
       "42                           0.73500          0.42       1.071  \n",
       "43                           0.63105          0.35       1.152  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_b   !!!! SREDITI DATUME U EXCEL ULAZU!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a50a2e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "Reindexing only valid with uniquely valued Index objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-40dbe135fb6b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfinal_data_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpredicted_data_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobserved_data_df\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfinal_data_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data_science\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    296\u001b[0m     )\n\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 298\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data_science\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    514\u001b[0m                     \u001b[0mobj_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m                         \u001b[0mindexers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\data_science\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   3169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3170\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3171\u001b[1;33m             raise InvalidIndexError(\n\u001b[0m\u001b[0;32m   3172\u001b[0m                 \u001b[1;34m\"Reindexing only valid with uniquely valued Index objects\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3173\u001b[0m             )\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects"
     ]
    }
   ],
   "source": [
    "final_data_df = pd.concat([predicted_data_df, observed_data_df], axis = 1)\n",
    "final_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3246426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter_blasting(results_df, x_values, y_values_1, y_values_2, \n",
    "                          xlabel=\"Resulting Cavity [m$^3$]\", ylabel=\"Explosive Charge Mass [kg]\", model_number = \"Model_1\"):\n",
    "    \n",
    "    sns.set(font=\"Palatino Linotype\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14,8), dpi=300)\n",
    "    results_df[\"Date_formated\"] = results_df[\"Date\"].dt.strftime(\"%d.%m.%Y\") \n",
    "        \n",
    "\n",
    "    \n",
    "    ax1 = sns.scatterplot(data = results_df, x=x_values, y=y_values_1,  s=250,  \n",
    "                         label=\"Predicted\", hue=\"Date_formated\", style=\"Date_formated\",  \n",
    "                         markers=[\"p\", \"o\",], palette = \"Oranges\")\n",
    " \n",
    "    ax2 = sns.scatterplot(data = results_df, x=x_values, y=y_values_2,  s=200,  \n",
    "                         label=\"Observed\", hue=\"Date_formated\", style=\"Date_formated\", \n",
    "                         markers=[\"P\", \"X\",], palette = \"ocean_r\")\n",
    "    \n",
    "\n",
    "    ax.set_xlabel(xlabel, size=18,)\n",
    "    ax.set_ylabel(ylabel, size=18)\n",
    "    ax.tick_params(grid_alpha=0.9, labelsize=16)\n",
    "    #plt.legend(fontsize=14)\n",
    "    ax.legend(fontsize=17)\n",
    "    ax.set_title(model_number, fontsize = 18)\n",
    "\n",
    "    plt.savefig(\"Figure_\"+xlabel[:-4]+\"_\"+ ylabel[:-4]+\".png\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d847002",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_data_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-879c6c850c38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#ylabel = \"Stemming Legth [m]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mresults_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_data_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m17\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mplot_scatter_blasting\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_values_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_values_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mylabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_number\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_number\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'final_data_df' is not defined"
     ]
    }
   ],
   "source": [
    "model_number = \"Model_1\"\n",
    "x_values = \"Proširenje\"\n",
    "y_values_1 = \"ECM_pred\"\n",
    "y_values_2 = \"Explosive\\nCharge Mass\"\n",
    "xlabel = \"Borehole Expansion [m]\"\n",
    "#xlabel = \"Resulting Cavity [m$^3$]\"\n",
    "label = \"Explosive Charge Mass [kg]\"\n",
    "#ylabel = \"Stemming Legth [m]\"\n",
    "\n",
    "results_df = final_data_df[:-17]\n",
    "\n",
    "plot_scatter_blasting(results_df, x_values, y_values_1, y_values_2, xlabel, ylabel, model_number=model_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02613758",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-c6e1e69bfc9b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresults_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'results_df' is not defined"
     ]
    }
   ],
   "source": [
    "results_df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0057a3",
   "metadata": {},
   "source": [
    "## Calculating metrics and results of modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4824f422",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_data_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-cacb6217bc03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfinal_data_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_data_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfinal_data_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'final_data_df' is not defined"
     ]
    }
   ],
   "source": [
    "final_data_df = final_data_df.iloc[:, :5]\n",
    "final_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f2c19bda",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_data_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-261302eec9dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfinal_data_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Date\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"2016-07-20\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'final_data_df' is not defined"
     ]
    }
   ],
   "source": [
    "final_data_df[\"Date\"] == \"2016-07-20\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99560f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "id": "57eea644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.779300548717969e-05\n",
      "0.0009161495816978543\n",
      "0.007575067418085587\n",
      "0.009147943615292507\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-900-6fe429c0a897>:4: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  nse = 1-(np.sum(np.square(predicted - observed))/np.sum(np.square(observed - np.mean(observed))))\n",
      "<ipython-input-900-6fe429c0a897>:11: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  r2 = ss_res/ss_tot\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>NSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013204</td>\n",
       "      <td>0.114907</td>\n",
       "      <td>-3.931010</td>\n",
       "      <td>0.041252</td>\n",
       "      <td>0.087519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.030987</td>\n",
       "      <td>0.176030</td>\n",
       "      <td>0.433747</td>\n",
       "      <td>0.828062</td>\n",
       "      <td>0.127573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007238</td>\n",
       "      <td>0.085074</td>\n",
       "      <td>-inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.071917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MSE      RMSE       NSE        R2       MAE\n",
       "0  0.013204  0.114907 -3.931010  0.041252  0.087519\n",
       "1  0.030987  0.176030  0.433747  0.828062  0.127573\n",
       "2  0.007238  0.085074      -inf       NaN  0.071917"
      ]
     },
     "execution_count": 931,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_metrics_test = get_metrics(final_data_df.loc[final_data_df[\"Date\"] == \"2016-08-31\"][\"Stemming_len_pred\"], \n",
    "                                final_data_df.loc[final_data_df[\"Date\"] == \"2016-08-31\"][\"Stemming Length\"])\n",
    "\n",
    "stem_metrics_valid = get_metrics(final_data_df.loc[final_data_df[\"Date\"] == \"2015-06-12\"][\"Stemming_len_pred\"], \n",
    "                                final_data_df.loc[final_data_df[\"Date\"] == \"2015-06-12\"][\"Stemming Length\"])\n",
    "\n",
    "stem_metrics_train = get_metrics(final_data_df.loc[final_data_df[\"Date\"] == \"2016-07-20\"][\"Stemming_len_pred\"], \n",
    "                                final_data_df.loc[final_data_df[\"Date\"] == \"2016-07-20\"][\"Stemming Length\"])\n",
    "\n",
    "stem_metrics_df = pd.DataFrame.from_dict([stem_metrics_test, stem_metrics_valid, stem_metrics_train ],)\n",
    "stem_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "id": "83a91a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10445614188045863\n",
      "0.12045972184701398\n",
      "0.09427221706715767\n",
      "0.11496922671794894\n",
      "0.18568254217157124\n",
      "0.24794967875761145\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>NSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.023557</td>\n",
       "      <td>0.153484</td>\n",
       "      <td>0.616879</td>\n",
       "      <td>0.867146</td>\n",
       "      <td>0.127683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.144897</td>\n",
       "      <td>0.380654</td>\n",
       "      <td>0.306342</td>\n",
       "      <td>0.819978</td>\n",
       "      <td>0.287096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.028703</td>\n",
       "      <td>0.169419</td>\n",
       "      <td>0.567965</td>\n",
       "      <td>0.748872</td>\n",
       "      <td>0.148336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MSE      RMSE       NSE        R2       MAE\n",
       "0  0.023557  0.153484  0.616879  0.867146  0.127683\n",
       "1  0.144897  0.380654  0.306342  0.819978  0.287096\n",
       "2  0.028703  0.169419  0.567965  0.748872  0.148336"
      ]
     },
     "execution_count": 932,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_metrics_test = get_metrics(final_data_df.loc[final_data_df[\"Date\"] == \"2016-08-31\"][\"ECM_pred\"], \n",
    "                                final_data_df.loc[final_data_df[\"Date\"] == \"2016-08-31\"][\"Explosive\\nCharge Mass\"])\n",
    "\n",
    "exp_metrics_valid = get_metrics(final_data_df.loc[final_data_df[\"Date\"] == \"2015-06-12\"][\"ECM_pred\"], \n",
    "                                final_data_df.loc[final_data_df[\"Date\"] == \"2015-06-12\"][\"Explosive\\nCharge Mass\"])\n",
    "\n",
    "exp_metrics_train = get_metrics(final_data_df.loc[final_data_df[\"Date\"] == \"2016-07-20\"][\"ECM_pred\"], \n",
    "                                final_data_df.loc[final_data_df[\"Date\"] == \"2016-07-20\"][\"Explosive\\nCharge Mass\"])\n",
    "\n",
    "explosive_metrics_df = pd.DataFrame([exp_metrics_test, exp_metrics_valid, exp_metrics_train ])\n",
    "explosive_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "id": "75e60a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.concat([explosive_metrics_df, stem_metrics_df], axis = 0)\n",
    "\n",
    "metrics_df = metrics_df[[\"MSE\",]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "id": "3f073057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 923,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics_df.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db21283f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d805ef8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d128cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
